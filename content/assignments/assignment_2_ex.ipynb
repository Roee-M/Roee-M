{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2 - Decision Trees"
      ],
      "metadata": {
        "id": "T6eOeeoW2z5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before you begin\n",
        "\n",
        "Remember to:\n",
        "\n",
        "1. Make your own copy of the notebook by pressing the \"Copy to drive\" button.\n",
        "2. Expend all cells by pressing **Ctrl+[**\n",
        "\n",
        "### Your IDs\n",
        "\n",
        "✍️ Fill in your IDs in the cell below:"
      ],
      "metadata": {
        "id": "jNM_agp12z5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "## Fill in your IDs (as a string)\n",
        "student1_id = '...'\n",
        "student2_id = '...'\n",
        "## %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%\n",
        "\n",
        "print('Hello ' + student1_id + ' & ' + student2_id)"
      ],
      "metadata": {
        "id": "kTEGvUUX2z5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Packages"
      ],
      "metadata": {
        "id": "WJudD7Dk2z5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  # Numerical package (mainly multi-dimensional arrays and linear algebra)\n",
        "import pandas as pd  # A package for working with data frames\n",
        "import matplotlib.pyplot as plt  # A plotting package\n",
        "\n",
        "## Setup matplotlib to output figures into the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "## Set some default values of the the matplotlib plots\n",
        "plt.rcParams['figure.figsize'] = (6.0, 6.0)  # Set default plot's sizes\n",
        "plt.rcParams['figure.dpi'] = 120  # Set default plot's dpi (increase fonts' size)\n",
        "plt.rcParams['axes.grid'] = True  # Show grid by default in figures"
      ],
      "metadata": {
        "id": "I9IlGVgl2z5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seoul Bike Sharing Demand Dataset\n",
        "\n",
        "Similar to the previous assignment, we will again work with the bike sharing dataset trying to predict the number of rented bikes in each hour according to the day of the week, the time of day and the weather."
      ],
      "metadata": {
        "id": "OH73yp2o2z5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "vfDODr1D2z5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_location = 'https://technion046195.netlify.app/datasets/bike_demand.csv'\n",
        "\n",
        "## Loading the data\n",
        "dataset = pd.read_csv(dataset_location)"
      ],
      "metadata": {
        "id": "vNkSPJNu2z5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall plot the dataset again"
      ],
      "metadata": {
        "id": "OIxoT4nQ2z5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "qe_IkISx2z5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✍️ Again we shall store all the relevant fields in a list named \"x_fields\". Fill in the name of the relevant fields we would like to use for our prediction (reminder: we do not want to use the \"Date\" field).\n",
        "\n",
        "- You can basically copy this line from the last assignment."
      ],
      "metadata": {
        "id": "Bhl0afmr2z5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_field = 'Rented Bike Count'\n",
        "\n",
        "## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "## Fill in the name of the relevant fields.\n",
        "x_fields = ['Hour', 'Temperature(°C)', ...\n",
        "## %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%"
      ],
      "metadata": {
        "id": "Ko5paRFA2z5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-test split\n",
        "\n",
        "We shall divide the dataset into 80% train and 20% train.\n",
        "\n",
        "✍️ Copy the code from the last assignment in order to split the dataset"
      ],
      "metadata": {
        "id": "pHldyRlU2z5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(dataset)  # The total number of samples in the dataset\n",
        "\n",
        "## Generate a random generator with a fixed seed\n",
        "rand_gen = np.random.RandomState(0)\n",
        "\n",
        "## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "## Generating a shuffled vector of indices\n",
        "...\n",
        "\n",
        "## Split the indices into 80% train (full) / 20% test\n",
        "...\n",
        "train_full_indices = ...\n",
        "test_indices = ...\n",
        "## %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%\n",
        "\n",
        "## Extract the sub datasets from the full dataset using the calculated indices\n",
        "train_full_set = dataset.iloc[train_full_indices]\n",
        "test_set = dataset.iloc[test_indices]"
      ],
      "metadata": {
        "id": "QlIASHZh2z5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train - validation split\n",
        "\n",
        "We shall divide the train set into 75% train and 25% validation.\n",
        "\n",
        "✍️ Complete the following code to create a train-validation split similar to the train-test split above:"
      ],
      "metadata": {
        "id": "TUY9J0iv2z5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate a random generator with a fixed (different) seed\n",
        "rand_gen = np.random.RandomState(1)\n",
        "\n",
        "## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "## Generating a shuffled vector of indices\n",
        "...\n",
        "\n",
        "## Split the indices of the train (full) dataset into 75% train / 25% validation\n",
        "...\n",
        "train_indices = ...\n",
        "val_indices = ...\n",
        "## %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%\n",
        "\n",
        "## Extract the sub datasets from the full dataset using the calculated indices\n",
        "train_set = dataset.iloc[train_indices]\n",
        "val_set = dataset.iloc[val_indices]"
      ],
      "metadata": {
        "id": "SZpyi5IX2z5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting the features from the dataset\n",
        "\n",
        "✍️ Complete the following code to create the $X$ matrix and $\\boldsymbol{y}$ vector for a given dataset. In this case we only want one column per each field in \"x_fields\" (no high orders). The is not need to add a bias term."
      ],
      "metadata": {
        "id": "BzMyCYOD2z5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_x_y(dataset):\n",
        "    ## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "    features = []\n",
        "    for field in x_fields:\n",
        "        features.append(...\n",
        "    \n",
        "    x = ...\n",
        "    y = ...\n",
        "    ## %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%\n",
        "    return x, y\n",
        "\n",
        "x_train, y_train = extract_x_y(train_set)\n",
        "x_val, y_val = extract_x_y(val_set)\n",
        "x_train_full, y_train_full = extract_x_y(train_full_set)\n",
        "x_test, y_test = extract_x_y(test_set)"
      ],
      "metadata": {
        "id": "fbx6Z7LM2z5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Decision Tree for Regression\n",
        "\n",
        "In call we have shown how a to use a decision tree to solve classification tasks. In this assignment we will show how they can also be used to solve regression problems. Specifically we will show how to do so for the case of an MSE / RMSE loss function.\n",
        "\n",
        "In order to make our algorithm for building the trees useful for regression problems, we will make 2 adjustments:\n",
        "\n",
        "1. The criteria which we will be using to select the best node to add will be the MSE (or the RMSE), replacing the Gini / entropy criteria.\n",
        "2. The final prediction in the leafs of the tree will be selected as the mean of the labels of the samples reaching each leaf, when applying the decision tree to the train set. "
      ],
      "metadata": {
        "id": "lFCE6IIf2z5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Stump - A decision tree of depth 1\n",
        "\n",
        "We will start with a simple case of a tree of depth 1, i.e. a tree with a single split. Such decision trees are usually referred to as **stumps**. Since we are limiting our selves to splits of the form of $x_i\\geq\\alpha$, the stump has 4 parameters:\n",
        "\n",
        "- $i$: the index of the component of $\\boldsymbol{x}$ which we would like to compare.\n",
        "- $\\alpha$: the threshold.\n",
        "- The predictions for each of the two leafs.\n",
        "\n",
        "The following class implements a stump.\n",
        "\n",
        "- The values of $i$ and $\\alpha$ are fixed when the stump is created.\n",
        "- The prediction values in the leafs are updated when calling the \"fit\" method with a set of $X$ and $\\boldsymbol{y}$.\n",
        "- The split function is an auxiliary function which creates two sets of indices which can be used to  split the data according the the stump condition.\n",
        "- The predict method receives $X$ and produces a prediction $\\hat{\\boldsymbol{y}}$.\n",
        "\n",
        "✍️ Go over the code and complete the code in the fit method such that the stump will learn the optimal prediction in each leaf based on the given data (x and y).\n",
        "\n",
        "- Remember the optimal prediction in each node will be the mean value of the labels of the samples reaching each leaf.\n",
        "- The fit function has two \"if\" functions to check if the split didn't produce an empty split (using the \"any\" function). The values of the predictions should be updated only if the split is not empty, other wise the predictions should be left with their initial values (-1)."
      ],
      "metadata": {
        "id": "8GDZ0yVV2z5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Stump:\n",
        "    def __init__(self, field_num, threshold):\n",
        "        ## Initizalizing the stump with some fixed values of field_num (i) and threshold (alpha)\n",
        "        self.field_num = field_num\n",
        "        self.threshold = threshold\n",
        "        \n",
        "        self.true_leaf_prediciton = -1  ## This is a place holder until the fit function is called\n",
        "        self.false_leaf_prediction = -1  ## This is a place holder until the fit function is called\n",
        "    \n",
        "    def split(self, x):\n",
        "        ## An auxiliary function for generating indices for splitting the data.\n",
        "        true_indices = (x[:, self.field_num] >= self.threshold)\n",
        "        false_indices = (x[:, self.field_num] < self.threshold)\n",
        "        return true_indices, false_indices\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        true_indices, false_indices = self.split(x)\n",
        "        ## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "        if true_indices.any():\n",
        "            self.true_leaf_prediciton = ...\n",
        "        if false_indices.any():\n",
        "            self.false_leaf_prediction = ...\n",
        "        ## %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%\n",
        "\n",
        "    def predict(self, x):\n",
        "        y_hat = np.zeros(x.shape[0])\n",
        "        true_indices, false_indices = self.split(x)\n",
        "        y_hat[true_indices] = self.true_leaf_prediciton\n",
        "        y_hat[false_indices] = self.false_leaf_prediction\n",
        "        return y_hat\n",
        "\n",
        "## Test\n",
        "stump = Stump(0, 10)\n",
        "stump.fit(x_train, y_train)\n",
        "print(f'true_leaf_prediciton: {stump.true_leaf_prediciton}')\n",
        "print(f'false_leaf_prediction: {stump.false_leaf_prediction}')"
      ],
      "metadata": {
        "id": "89gfzFgs2z5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that you get results around 950 and 450 in the above cell.\n",
        "\n",
        "This function below uses a package named \"graphviz\" to plot stumps. You do not need to go over it."
      ],
      "metadata": {
        "id": "Kj8exgRv2z5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph  # A package for plothing graphs (of nodes and edges)\n",
        "def plot_stump(stump):\n",
        "    node_style = {'style': 'filled', 'fillcolor': '#DAE8FC', 'color': '#6C8EBF', 'penwidth': '3'}\n",
        "    edge_style = {'penwidth': '2'}\n",
        "\n",
        "    node_text = f'{x_fields[stump.field_num]} >= {int(stump.threshold)}'\n",
        "    \n",
        "    tree_graph = Digraph()\n",
        "    tree_graph.node('root', '<<I><B>x</B></I>>', shape='plaintext')\n",
        "    tree_graph.edge('root', 'node', **edge_style)\n",
        "    tree_graph.node('node', node_text, **node_style)\n",
        "    tree_graph.edge('node', 'node_0', 'No', **edge_style)\n",
        "    tree_graph.node('node_0', f'{int(stump.false_leaf_prediction)}', shape='plaintext')\n",
        "    tree_graph.edge('node', 'node_1', 'Yes', **edge_style)\n",
        "    tree_graph.node('node_1', f'{int(stump.true_leaf_prediciton)}', shape='plaintext')\n",
        "    return tree_graph"
      ],
      "metadata": {
        "id": "iKGF1Ahv2z5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_stump(stump)"
      ],
      "metadata": {
        "id": "sqkha8yg2z5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at some predictions"
      ],
      "metadata": {
        "id": "X1D6OF1H2z5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'x1 values (hour): {x_train[:10, 0]}')\n",
        "print(f'Predictions     : {stump.predict(x_train).astype(int)[:10]}')"
      ],
      "metadata": {
        "id": "C84gHCLe2z5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the RMSE\n",
        "\n",
        "Since we will use RMSE both to select the node to add at each step and to evaluated the out model, let's implement a function which calculated the RMSE for a given model and a dataset ($X$ and $\\boldsymbol{y}$).\n",
        "\n",
        "✍️ Complete the code below so that it will compute the RMSE of the model in the given dataset."
      ],
      "metadata": {
        "id": "tkC1_Nbe2z5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_model_rmse(model, x, y):\n",
        "    y_hat = model.predict(x)\n",
        "    ## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "    rmse = ...\n",
        "    ## %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%\n",
        "    return rmse\n",
        "\n",
        "calc_model_rmse(stump, x_train, y_train)"
      ],
      "metadata": {
        "id": "4B0g4QC_2z5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Searching for the best stump\n",
        "\n",
        "Since the greedy algorithm for growing the trees looks for the best stump in each step, we need to implement a function which find that stump for a given dataset. We will do so by going over all the possible stumps.\n",
        "\n",
        "✍️ Complete the code which searches for the best stump:"
      ],
      "metadata": {
        "id": "mQ27R0ZK2z5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_stump(x, y):\n",
        "    best_stump = None\n",
        "    best_score = np.inf\n",
        "    for field_num in range(x.shape[1]):  # Go over all fields\n",
        "        for val in x[:, field_num]:  # Go over all relevant threshold\n",
        "            ## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "            stump = ...  # Build a stump with the given field and threshold\n",
        "            ...  ## Do some additional processing\n",
        "            score = calc_model_rmse(stump, x, y) ## Calculate the RMSE score for the stump\n",
        "            if score < best_score: ## If it is better that the best stump so far store it as the best\n",
        "                best_stump = ...\n",
        "                best_score = ...\n",
        "            ## %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%\n",
        "    return best_stump, best_score\n",
        "\n",
        "best_stump, best_score = find_best_stump(x_train, y_train)\n",
        "print(best_score)\n",
        "plot_stump(best_stump)"
      ],
      "metadata": {
        "id": "asl9mLn82z5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you get a split according to the temperature."
      ],
      "metadata": {
        "id": "hbrQJ2uK2z5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deeper Trees\n",
        "\n",
        "Below is an implementation of a node in a general tree with an arbitrary depth. Each node object can be either a leaf or a split (like a stump). For the case where the node is a split it points to the two next nodes in the tree.\n",
        "\n",
        "Each node is initialized as a leaf with a fixed prediction and can later become a split in the growing process. When the growing function is called on a node which is a leaf, it uses the \"find_best_stump\" function to search for the optimal split which will replace the leaf. When the growing function is called on a node which is a split, it splits the data and calls the growing function on the child nodes.\n",
        "\n",
        "This class is already fully implemented including the growing function and the pruning function and it is built upon the function which we had defined so far. You are encouraged to go over it and try to make sure you understand how the growing process works and the pruning work."
      ],
      "metadata": {
        "id": "Z0sZlOeX2z5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, prediction):\n",
        "        self.is_leaf = True\n",
        "        \n",
        "        self.prediction = prediction\n",
        "\n",
        "        self.field_num = None\n",
        "        self.threshold = None\n",
        "        self.node_true = None\n",
        "        self.node_false = None\n",
        "    \n",
        "    def split(self, x):\n",
        "        true_indices = (x[:, self.field_num] >= self.threshold)\n",
        "        false_indices = (x[:, self.field_num] < self.threshold)\n",
        "        return true_indices, false_indices\n",
        "\n",
        "    def predict(self, x):\n",
        "        y_hat = np.zeros(x.shape[0])\n",
        "        if self.is_leaf:\n",
        "            y_hat[:] = self.prediction\n",
        "        else:\n",
        "            true_indices, false_indices = self.split(x)\n",
        "            y_hat[true_indices] = self.node_true.predict(x[true_indices])\n",
        "            y_hat[false_indices] = self.node_false.predict(x[false_indices])\n",
        "        return y_hat\n",
        "    \n",
        "    def grow_one_level(self, x, y):\n",
        "        if not self.is_leaf:\n",
        "            true_indices, false_indices = self.split(x)\n",
        "            self.node_true.grow_one_level(x[true_indices], y[true_indices])\n",
        "            self.node_false.grow_one_level(x[false_indices], y[false_indices])\n",
        "        else:\n",
        "            score_before = calc_model_rmse(self, x, y)\n",
        "            best_stump, best_score = find_best_stump(x, y)\n",
        "            if best_score < score_before:\n",
        "                self.is_leaf = False\n",
        "                self.field_num = best_stump.field_num\n",
        "                self.threshold = best_stump.threshold\n",
        "                self.node_true = Node(best_stump.true_leaf_prediciton)\n",
        "                self.node_false = Node(best_stump.false_leaf_prediction)\n",
        "    \n",
        "    def prune(self, x, y):\n",
        "        if not self.is_leaf:\n",
        "            true_indices, false_indices = self.split(x)\n",
        "            if not (true_indices.any() and false_indices.any()):\n",
        "                self.is_leaf = True\n",
        "            else:\n",
        "                self.node_true.prune(x[true_indices], y[true_indices])\n",
        "                self.node_false.prune(x[false_indices], y[false_indices])\n",
        "                if self.node_true.is_leaf and self.node_false.is_leaf:\n",
        "                    score_with = calc_model_rmse(self, x, y)\n",
        "                    self.is_leaf = True\n",
        "                    score_without = calc_model_rmse(self, x, y)\n",
        "                    if score_with < score_without:\n",
        "                        self.is_leaf = False"
      ],
      "metadata": {
        "id": "6DyU4KBN2z5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And a function to plot the tree:"
      ],
      "metadata": {
        "id": "BLvzc2Xp2z5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_tree(tree):\n",
        "    node_style = {'style': 'filled', 'fillcolor': '#DAE8FC', 'color': '#6C8EBF', 'penwidth': '3'}\n",
        "    edge_style = {'penwidth': '2'}\n",
        "\n",
        "    def add_node_to_tree(node, index):\n",
        "        if node.is_leaf:\n",
        "            tree_graph.node(index, f'{int(node.prediction)}', shape='plaintext')\n",
        "        else:\n",
        "            node_text = f'{x_fields[node.field_num]} >= {int(node.threshold)}'\n",
        "            tree_graph.node(index, node_text, **node_style)\n",
        "            tree_graph.edge(index, index + '_0', 'No', **edge_style)\n",
        "            add_node_to_tree(node.node_false, index + '_0')\n",
        "            tree_graph.edge(index, index + '_1', 'Yes', **edge_style)\n",
        "            add_node_to_tree(node.node_true, index + '_1')\n",
        "        \n",
        "    tree_graph = Digraph(comment='Tree')\n",
        "    tree_graph.format = 'png'\n",
        "    tree_graph.node('root', '<<I><B>x</B></I>>', shape='plaintext')\n",
        "    tree_graph.edge('root', 'node', **edge_style)\n",
        "    add_node_to_tree(tree, 'node')\n",
        "    \n",
        "    return tree_graph"
      ],
      "metadata": {
        "id": "Ng8ovWu-2z50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Growing a tree\n",
        "\n",
        "### Depth = 0\n",
        "\n",
        "We will start with a tree of 0 depth (only a single leaf). We will initialized it with the optimal constant predictor which is the mean value of the labels over all the train set."
      ],
      "metadata": {
        "id": "VrtMdFPd2z50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = Node(y_train.mean())\n",
        "print(f'The RMSE score in the train is: {calc_model_rmse(tree, x_train, y_train):.2f}')\n",
        "print(f'The RMSE score in the validation is: {calc_model_rmse(tree, x_val, y_val):.2f}')\n",
        "plot_tree(tree)"
      ],
      "metadata": {
        "id": "2yswHayf2z50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Depth = 1\n",
        "\n",
        "We will now call the \"grow_one_level\" function to add an extra layer to the tree:"
      ],
      "metadata": {
        "id": "OsreUk062z50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree.grow_one_level(x_train, y_train)\n",
        "print(f'The RMSE score in the train is: {calc_model_rmse(tree, x_train, y_train):.2f}')\n",
        "print(f'The RMSE score in the validation is: {calc_model_rmse(tree, x_val, y_val):.2f}')\n",
        "plot_tree(tree)"
      ],
      "metadata": {
        "id": "N9U43ENu2z50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Depth = 2"
      ],
      "metadata": {
        "id": "E6eeBVOs2z57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree.grow_one_level(x_train, y_train)\n",
        "print(f'The RMSE score in the train is: {calc_model_rmse(tree, x_train, y_train):.2f}')\n",
        "print(f'The RMSE score in the validation is: {calc_model_rmse(tree, x_val, y_val):.2f}')\n",
        "plot_tree(tree)"
      ],
      "metadata": {
        "id": "5VbPHhSY2z58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Depth = 3"
      ],
      "metadata": {
        "id": "DVclTdF22z58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree.grow_one_level(x_train, y_train)\n",
        "print(f'The RMSE score in the train is: {calc_model_rmse(tree, x_train, y_train):.2f}')\n",
        "print(f'The RMSE score in the validation is: {calc_model_rmse(tree, x_val, y_val):.2f}')\n",
        "plot_tree(tree)"
      ],
      "metadata": {
        "id": "nVuPAsiD2z58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Growing until depth = 13\n",
        "\n",
        "We shall stop plotting the tree from here."
      ],
      "metadata": {
        "id": "DUtQFbXR2z58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for level in range(4, 14):\n",
        "    print(f'\\nLevel {level}:')\n",
        "    tree.grow_one_level(x_train, y_train)\n",
        "    print(f'The RMSE score in the train is: {calc_model_rmse(tree, x_train, y_train):.2f}')\n",
        "    print(f'The RMSE score in the validation is: {calc_model_rmse(tree, x_val, y_val):.2f}')"
      ],
      "metadata": {
        "id": "aj93ku1R2z59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pruning\n",
        "\n",
        "We can now use the pruning function to prune the tree using the validation set."
      ],
      "metadata": {
        "id": "Zs-HvJC32z59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree.prune(x_val, y_val)\n",
        "print(f'The RMSE score in the train is: {calc_model_rmse(tree, x_train, y_train):.2f}')\n",
        "print(f'The RMSE score in the validation is: {calc_model_rmse(tree, x_val, y_val):.2f}')"
      ],
      "metadata": {
        "id": "fN8dXJEt2z59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final evaluation\n",
        "\n",
        "Evaluate the model using the test set\n",
        "\n",
        "✍️ Complete the code below the evaluate the RMSE on the test set"
      ],
      "metadata": {
        "id": "bTXAdxdz2z59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "print(f'The RMSE score in the test is: {...\n",
        "## %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%"
      ],
      "metadata": {
        "id": "dxqqPl7d2z5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision trees in scikit-learn\n",
        "\n",
        "The scikit-learn package also has an implementation for decision trees. Use the documentation of the [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) object and use in to grow a tree of depth 13. Evaluate the train and validation errors on the new trained, and check that you get the same results as with implementation in this notebook (up to around 1% difference).\n",
        "\n",
        "- Note that the run time of the scikit-learn implementation is significantly faster, mainly due to a more efficient implementation of the search for the best split.\n",
        "\n",
        "✍️ Complete the code below to train and evaluate a decision tree of depth 13 using the scikit-learn package:"
      ],
      "metadata": {
        "id": "mngATcw82z5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "## %%%%%%%%%%%%%%% Your code here - Begin %%%%%%%%%%%%%%%\n",
        "tree2 = DecisionTreeRegressor(...\n",
        "...\n",
        "# %%%%%%%%%%%%%%% Your code here - End %%%%%%%%%%%%%%%%%\n",
        "\n",
        "print(f'The RMSE score in the train is: {calc_model_rmse(tree2, x_train, y_train):.2f}')\n",
        "print(f'The RMSE score in the validation is: {calc_model_rmse(tree2, x_val, y_val):.2f}')"
      ],
      "metadata": {
        "id": "h5zwk5Jf2z5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission\n",
        "\n",
        "To submit your code download it as a **ipynb** file from Colab, and upload it to the course's website (Moodle). You can download this code by selecting **Download .ipynb** from the **file** menu."
      ],
      "metadata": {
        "id": "f0wlKOBL2z5_"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}